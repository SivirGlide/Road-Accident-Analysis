{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6d1922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Categorical Data to Numerical using One-Hot Encoding\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ONE-HOT ENCODING CATEGORICAL VARIABLES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Identify categorical columns (object type)\n",
    "all_categorical_cols = data.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Exclude columns that shouldn't be one-hot encoded\n",
    "exclude_from_encoding = [\n",
    "    'Accident_Index',           # Unique identifier\n",
    "    'LSOA_of_Accident_Location', # High cardinality location code\n",
    "    'Location_Easting_OSGR',    # Coordinate data\n",
    "    'Location_Northing_OSGR'    # Coordinate data\n",
    "]\n",
    "\n",
    "# Filter to only columns we want to encode\n",
    "categorical_cols = [col for col in all_categorical_cols if col not in exclude_from_encoding]\n",
    "\n",
    "print(f\"\\nOriginal dataset shape: {data.shape}\")\n",
    "print(f\"\\nCategorical columns to encode ({len(categorical_cols)}):\")\n",
    "for col in categorical_cols:\n",
    "    n_unique = data[col].nunique()\n",
    "    print(f\"  • {col:35s} - {n_unique} unique values\")\n",
    "\n",
    "print(f\"\\nColumns excluded from encoding ({len(exclude_from_encoding)}):\")\n",
    "for col in exclude_from_encoding:\n",
    "    if col in all_categorical_cols:\n",
    "        print(f\"  • {col}\")\n",
    "\n",
    "# Apply one-hot encoding only to selected columns\n",
    "data_encoded = pd.get_dummies(data, columns=categorical_cols, drop_first=False, dtype=int)\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"ENCODING COMPLETE\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"New dataset shape: {data_encoded.shape}\")\n",
    "print(f\"Columns added: {data_encoded.shape[1] - data.shape[1]}\")\n",
    "print(f\"Categorical columns encoded: {len(categorical_cols)}\")\n",
    "\n",
    "# Update data variable\n",
    "data = data_encoded\n",
    "\n",
    "# Display sample of new columns\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"SAMPLE OF ENCODED COLUMNS (first 20):\")\n",
    "print(\"-\" * 70)\n",
    "encoded_cols = [col for col in data.columns if any(cat in col for cat in categorical_cols)]\n",
    "for col in encoded_cols[:20]:\n",
    "    print(f\"  • {col}\")\n",
    "if len(encoded_cols) > 20:\n",
    "    print(f\"  ... and {len(encoded_cols) - 20} more encoded columns\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"Data is now ready for modeling!\")\n",
    "print(f\"Final shape: {data.shape}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d215bd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means Clustering for Optimal Hospital Placement\n",
    "# With weighting based on Speed Limit and Road Density\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial import distance_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION: Set number of clusters and weighting parameters\n",
    "# ============================================================================\n",
    "K = 4  # <- CHANGE THIS VALUE to adjust number of hospital locations\n",
    "\n",
    "# Weighting configuration\n",
    "SPEED_WEIGHT_ENABLED = True      # Enable/disable speed limit weighting\n",
    "DENSITY_WEIGHT_ENABLED = True    # Enable/disable road density weighting\n",
    "DENSITY_RADIUS_KM = 2.5          # Radius (in km) for calculating local accident density\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"K-MEANS CLUSTERING FOR OPTIMAL HOSPITAL PLACEMENT (K={K})\")\n",
    "print(f\"Speed weighting: {'ON' if SPEED_WEIGHT_ENABLED else 'OFF'}\")\n",
    "print(f\"Density weighting: {'ON' if DENSITY_WEIGHT_ENABLED else 'OFF'} (radius={DENSITY_RADIUS_KM}km)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Prepare Spatial Data with Weighting\n",
    "# ============================================================================\n",
    "print(\"\\n[STEP 1] Preparing Spatial Data with Speed Limit and Density Weighting\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Recreate Speed_Limit_Grouped from one-hot encoded columns\n",
    "data_cluster = data.copy()\n",
    "\n",
    "# Reconstruct Speed_Limit_Grouped\n",
    "speed_cols = [col for col in data.columns if 'Speed_Limit_Grouped_' in col]\n",
    "for col in speed_cols:\n",
    "    speed_group = col.replace('Speed_Limit_Grouped_', '')\n",
    "    data_cluster.loc[data[col] == 1, 'Speed_Limit_Grouped'] = speed_group\n",
    "\n",
    "# Create clustering dataset with required columns\n",
    "clustering_data = data_cluster[['Longitude', 'Latitude', 'Speed_Limit_Grouped']].copy()\n",
    "\n",
    "# Initialize combined weight as 1.0 (no weighting)\n",
    "clustering_data['Combined_Weight'] = 1.0\n",
    "\n",
    "# ============================================================================\n",
    "# Speed Limit Weighting\n",
    "# ============================================================================\n",
    "if SPEED_WEIGHT_ENABLED:\n",
    "    speed_weights = {\n",
    "        '30_or_less': 1.0,    # Baseline (no extra weight)\n",
    "        '40-50': 1.1,          # Slight increase (10% more weight)\n",
    "        '60_plus': 1.2         # Modest increase (20% more weight)\n",
    "    }\n",
    "    clustering_data['Speed_Weight'] = clustering_data['Speed_Limit_Grouped'].map(speed_weights).fillna(1.0)\n",
    "    clustering_data['Combined_Weight'] *= clustering_data['Speed_Weight']\n",
    "    print(\"Speed limit weighting applied\")\n",
    "else:\n",
    "    clustering_data['Speed_Weight'] = 1.0\n",
    "\n",
    "# ============================================================================\n",
    "# Road Density Weighting (Local Accident Density)\n",
    "# ============================================================================\n",
    "if DENSITY_WEIGHT_ENABLED:\n",
    "    print(f\"\\nCalculating local accident density (radius={DENSITY_RADIUS_KM}km)...\")\n",
    "    \n",
    "    # Convert lat/lon to approximate distances (1 degree ≈ 111km at equator)\n",
    "    # For small areas, this approximation is sufficient\n",
    "    coords = clustering_data[['Longitude', 'Latitude']].values\n",
    "    \n",
    "    # Calculate pairwise distances (in degrees)\n",
    "    distances = distance_matrix(coords, coords)\n",
    "    \n",
    "    # Convert radius from km to degrees (approximate)\n",
    "    radius_degrees = DENSITY_RADIUS_KM / 111.0\n",
    "    \n",
    "    # Count neighbors within radius for each point\n",
    "    neighbors_within_radius = (distances <= radius_degrees).sum(axis=1) - 1  # Subtract 1 to exclude self\n",
    "    \n",
    "    # Normalize density to create weights (higher density = higher weight)\n",
    "    # Min-max normalization to range [1.0, 1.5]\n",
    "    min_neighbors = neighbors_within_radius.min()\n",
    "    max_neighbors = neighbors_within_radius.max()\n",
    "    \n",
    "    if max_neighbors > min_neighbors:\n",
    "        density_weights = 1.0 + 0.5 * (neighbors_within_radius - min_neighbors) / (max_neighbors - min_neighbors)\n",
    "    else:\n",
    "        density_weights = np.ones(len(neighbors_within_radius))\n",
    "    \n",
    "    clustering_data['Density_Weight'] = density_weights\n",
    "    clustering_data['Neighbors_Count'] = neighbors_within_radius\n",
    "    clustering_data['Combined_Weight'] *= clustering_data['Density_Weight']\n",
    "    \n",
    "    print(f\"  Min neighbors within {DENSITY_RADIUS_KM}km: {min_neighbors}\")\n",
    "    print(f\"  Max neighbors within {DENSITY_RADIUS_KM}km: {max_neighbors}\")\n",
    "    print(f\"  Mean neighbors: {neighbors_within_radius.mean():.1f}\")\n",
    "    print(\"Road density weighting applied\")\n",
    "else:\n",
    "    clustering_data['Density_Weight'] = 1.0\n",
    "    clustering_data['Neighbors_Count'] = 0\n",
    "\n",
    "# ============================================================================\n",
    "# Summary Statistics\n",
    "# ============================================================================\n",
    "print(f\"\\nTotal accidents to cluster: {len(clustering_data)}\")\n",
    "print(f\"\\nSpeed limit distribution:\")\n",
    "print(clustering_data['Speed_Limit_Grouped'].value_counts())\n",
    "print(f\"\\nCombined weight range: {clustering_data['Combined_Weight'].min():.2f} - {clustering_data['Combined_Weight'].max():.2f}\")\n",
    "print(f\"Mean combined weight: {clustering_data['Combined_Weight'].mean():.2f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: Apply K-Means with Sample Weighting\n",
    "# ============================================================================\n",
    "print(f\"\\n[STEP 2] Applying K-Means Clustering (k={K})\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Use UNWEIGHTED coordinates for clustering, but use sample_weight parameter\n",
    "X = clustering_data[['Longitude', 'Latitude']].values\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply K-Means with k=K and combined weights\n",
    "kmeans = KMeans(n_clusters=K, random_state=42, n_init=10)\n",
    "clustering_data['Cluster'] = kmeans.fit_predict(X_scaled, sample_weight=clustering_data['Combined_Weight'].values)\n",
    "\n",
    "# Get cluster centers in original coordinate space\n",
    "cluster_centers_scaled = kmeans.cluster_centers_\n",
    "optimal_hospital_locations = scaler.inverse_transform(cluster_centers_scaled)\n",
    "\n",
    "print(\"Clustering complete!\")\n",
    "print(f\"Number of clusters: {K}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: Cluster Analysis\n",
    "# ============================================================================\n",
    "print(\"\\n[STEP 3] Cluster Analysis\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i in range(K):\n",
    "    cluster_data = clustering_data[clustering_data['Cluster'] == i]\n",
    "    n_accidents = len(cluster_data)\n",
    "    pct = (n_accidents / len(clustering_data)) * 100\n",
    "    \n",
    "    # Speed distribution in cluster\n",
    "    speed_dist = cluster_data['Speed_Limit_Grouped'].value_counts()\n",
    "    \n",
    "    print(f\"\\nCluster {i}:\")\n",
    "    print(f\"  Number of accidents: {n_accidents} ({pct:.1f}%)\")\n",
    "    print(f\"  Optimal Hospital Location (Centroid):\")\n",
    "    print(f\"    Longitude: {optimal_hospital_locations[i][0]:.6f}\")\n",
    "    print(f\"    Latitude:  {optimal_hospital_locations[i][1]:.6f}\")\n",
    "    print(f\"  Average combined weight: {cluster_data['Combined_Weight'].mean():.2f}\")\n",
    "    \n",
    "    if SPEED_WEIGHT_ENABLED:\n",
    "        print(f\"  Average speed weight: {cluster_data['Speed_Weight'].mean():.2f}\")\n",
    "    \n",
    "    if DENSITY_WEIGHT_ENABLED:\n",
    "        print(f\"  Average density weight: {cluster_data['Density_Weight'].mean():.2f}\")\n",
    "        print(f\"  Average neighbors within {DENSITY_RADIUS_KM}km: {cluster_data['Neighbors_Count'].mean():.1f}\")\n",
    "    \n",
    "    print(f\"  Speed limit distribution:\")\n",
    "    for speed, count in speed_dist.items():\n",
    "        print(f\"    {speed}: {count} ({count/n_accidents*100:.1f}%)\")\n",
    "    print(f\"  Longitude range: {cluster_data['Longitude'].min():.6f} to {cluster_data['Longitude'].max():.6f}\")\n",
    "    print(f\"  Latitude range:  {cluster_data['Latitude'].min():.6f} to {cluster_data['Latitude'].max():.6f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: Visualization\n",
    "# ============================================================================\n",
    "print(\"\\n[STEP 4] Visualizing Results\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# Define colors (cycle through if K > 10)\n",
    "color_palette = ['red', 'blue', 'green', 'orange', 'purple', 'brown', 'pink', 'gray', 'olive', 'cyan']\n",
    "colors = color_palette * ((K // len(color_palette)) + 1)\n",
    "\n",
    "# ============================================================================\n",
    "# Plot 1: Cluster Assignment\n",
    "# ============================================================================\n",
    "for i in range(K):\n",
    "    cluster_points = clustering_data[clustering_data['Cluster'] == i]\n",
    "    axes[0].scatter(cluster_points['Longitude'], cluster_points['Latitude'], \n",
    "                    c=colors[i], alpha=0.5, s=30, label=f'Cluster {i} ({len(cluster_points)} accidents)')\n",
    "\n",
    "# Plot optimal hospital locations (centroids)\n",
    "axes[0].scatter(optimal_hospital_locations[:, 0], optimal_hospital_locations[:, 1], \n",
    "                c='black', marker='*', s=500, edgecolors='yellow', linewidths=2,\n",
    "                label='Optimal Hospital Locations', zorder=5)\n",
    "\n",
    "# Annotate hospital locations\n",
    "for i in range(K):\n",
    "    axes[0].annotate(f'Hospital {i}', \n",
    "                     xy=(optimal_hospital_locations[i][0], optimal_hospital_locations[i][1]),\n",
    "                     xytext=(10, 10), textcoords='offset points',\n",
    "                     fontsize=12, fontweight='bold',\n",
    "                     bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.7))\n",
    "\n",
    "axes[0].set_xlabel('Longitude', fontsize=12)\n",
    "axes[0].set_ylabel('Latitude', fontsize=12)\n",
    "axes[0].set_title(f'Cluster Assignment (k={K})', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(loc='best', fontsize=9)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# ============================================================================\n",
    "# Plot 2: Density Heatmap (if density weighting enabled)\n",
    "# ============================================================================\n",
    "if DENSITY_WEIGHT_ENABLED:\n",
    "    scatter = axes[1].scatter(clustering_data['Longitude'], clustering_data['Latitude'], \n",
    "                              c=clustering_data['Density_Weight'], cmap='YlOrRd', \n",
    "                              alpha=0.6, s=40, edgecolors='black', linewidths=0.3)\n",
    "    \n",
    "    # Plot hospital locations on density map\n",
    "    axes[1].scatter(optimal_hospital_locations[:, 0], optimal_hospital_locations[:, 1], \n",
    "                    c='blue', marker='*', s=500, edgecolors='white', linewidths=2,\n",
    "                    label='Hospital Locations', zorder=5)\n",
    "    \n",
    "    plt.colorbar(scatter, ax=axes[1], label='Density Weight')\n",
    "    axes[1].set_xlabel('Longitude', fontsize=12)\n",
    "    axes[1].set_ylabel('Latitude', fontsize=12)\n",
    "    axes[1].set_title(f'Accident Density Heatmap (radius={DENSITY_RADIUS_KM}km)', fontsize=14, fontweight='bold')\n",
    "    axes[1].legend(loc='best', fontsize=10)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "else:\n",
    "    # Just show speed weights if density disabled\n",
    "    scatter = axes[1].scatter(clustering_data['Longitude'], clustering_data['Latitude'], \n",
    "                              c=clustering_data['Speed_Weight'], cmap='coolwarm', \n",
    "                              alpha=0.6, s=40, edgecolors='black', linewidths=0.3)\n",
    "    \n",
    "    axes[1].scatter(optimal_hospital_locations[:, 0], optimal_hospital_locations[:, 1], \n",
    "                    c='black', marker='*', s=500, edgecolors='yellow', linewidths=2,\n",
    "                    label='Hospital Locations', zorder=5)\n",
    "    \n",
    "    plt.colorbar(scatter, ax=axes[1], label='Speed Weight')\n",
    "    axes[1].set_xlabel('Longitude', fontsize=12)\n",
    "    axes[1].set_ylabel('Latitude', fontsize=12)\n",
    "    axes[1].set_title('Speed Limit Weight Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[1].legend(loc='best', fontsize=10)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: Recommendations\n",
    "# ============================================================================\n",
    "print(\"\\n[STEP 5] Hospital Placement Recommendations\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i in range(K):\n",
    "    cluster_data = clustering_data[clustering_data['Cluster'] == i]\n",
    "    high_speed_count = len(cluster_data[cluster_data['Speed_Limit_Grouped'] == '60_plus'])\n",
    "    high_speed_pct = (high_speed_count / len(cluster_data) * 100) if len(cluster_data) > 0 else 0\n",
    "    \n",
    "    print(f\"\\nHospital {i} Location:\")\n",
    "    print(f\"  Coordinates: ({optimal_hospital_locations[i][1]:.6f}, {optimal_hospital_locations[i][0]:.6f})\")\n",
    "    print(f\"  Will serve: {len(cluster_data)} accidents\")\n",
    "    print(f\"  High-speed road accidents (60+): {high_speed_count} ({high_speed_pct:.1f}%)\")\n",
    "    \n",
    "    if DENSITY_WEIGHT_ENABLED:\n",
    "        print(f\"  Average local density: {cluster_data['Neighbors_Count'].mean():.1f} accidents within {DENSITY_RADIUS_KM}km\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"Clustering complete! {K} hospital locations optimized.\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Add cluster labels back to main dataset (matching by index)\n",
    "data = data.reset_index(drop=True)\n",
    "clustering_data = clustering_data.reset_index(drop=True)\n",
    "data['Hospital_Cluster'] = clustering_data['Cluster']"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
